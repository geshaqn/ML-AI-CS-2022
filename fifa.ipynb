{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa1b304-abf2-4414-aa8b-d15632f8b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213f293-e1c6-45c8-93c6-10fccba43791",
   "metadata": {},
   "source": [
    "Новиков Г.К., 625.\n",
    "\n",
    "Загрузка данных. Исходный датасет содержит информацию о ~18к футболистах и их характеристиках из игры FIFA 19 (думаю, не должен быть заезженным, к тому же, я люблю футбол). Рассматриваем только игроков с действующим контрактом (поле Wage не пустое и не равно 0) и только полевых игроков (Position!='GK'). Задача - предсказать потенциал игрока по его подробным характеристикам (дриблинг, скорость и т.п.), зарплате, цене, возрасту и общему рейтингу. Пробуем модели для регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bf612b-b60d-4bd7-b9e5-ee6d55a7ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('football-players.txt',encoding='utf-8')\n",
    "labels=[a.replace('\\t\\n','') for a in f.readline().split(',')]\n",
    "data_labels=['Age','Overall','Value','Wage','International Reputation','Crossing','Finishing','HeadingAccuracy','ShortPassing','Volleys','Dribbling','Curve','FKAccuracy','LongPassing','BallControl','Acceleration','SprintSpeed','Agility','Reactions','Balance','ShotPower','Jumping','Stamina','Strength','LongShots','Aggression','Interceptions','Positioning','Vision','Penalties','Composure','Marking','StandingTackle','SlidingTackle']\n",
    "target_label=['Potential']\n",
    "target_data=[]\n",
    "data_table=[]\n",
    "for s in f:\n",
    "    if 'GK' in s:\n",
    "        continue\n",
    "    attr=s.split(',')\n",
    "    data=[]\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] not in data_labels:\n",
    "            if labels[i] in target_label:\n",
    "                target_data.append(int(attr[i]))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if labels[i]=='Wage' or labels[i]=='Value':\n",
    "                if attr[i]=='':\n",
    "                    data=[]\n",
    "                    break\n",
    "                st=attr[i].replace('€','')\n",
    "                if 'M' in st:\n",
    "                    data.append(float(st.replace('M',''))*1000000)\n",
    "                elif 'K' in st:\n",
    "                    data.append(float(st.replace('K',''))*1000)\n",
    "                else:\n",
    "                    data=[]\n",
    "                    break\n",
    "            else:\n",
    "                if (i>25):\n",
    "                    if attr[i+1]=='':\n",
    "                        data=[]\n",
    "                        break\n",
    "                    data.append(int(attr[i+1]))\n",
    "                else:\n",
    "                    if attr[i]=='':\n",
    "                        data=[]\n",
    "                        break\n",
    "                    data.append(int(attr[i]))\n",
    "    if data!=[]:\n",
    "        data_table.append(data)\n",
    "    if len(target_data)!=len(data_table):\n",
    "        target_data.pop()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743d888-63c5-41b8-a03e-6b6b380c0f29",
   "metadata": {},
   "source": [
    "Дальше поделим датасет на train и test и подготовим его. Test ~10% от всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddb3c3a-a41e-43e2-a912-a00e71cbedf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: len=14340, avg_target=71.52350069735007\n",
      "Test: len=1578, avg_target=71.5278833967047\n"
     ]
    }
   ],
   "source": [
    "train=[]\n",
    "train_target=[]\n",
    "test=[]\n",
    "test_target=[]\n",
    "for i in range(len(data_table)):\n",
    "    if randint(0,9)==0:\n",
    "        test.append(data_table[i])\n",
    "        test_target.append(target_data[i])\n",
    "    else:\n",
    "        train.append(data_table[i])\n",
    "        train_target.append(target_data[i])\n",
    "print('Train: len=',len(train),', avg_target=',sum(train_target)/len(train_target),sep='')\n",
    "print('Test: len=',len(test),', avg_target=',sum(test_target)/len(test_target),sep='')\n",
    "train=np.array(train)\n",
    "scaler=preprocessing.StandardScaler().fit(train)\n",
    "train=scaler.transform(train)\n",
    "train_target=np.array(train_target)\n",
    "test=np.array(test)\n",
    "test=scaler.transform(test)\n",
    "test_target=np.array(test_target)\n",
    "train_target=train_target/100\n",
    "test_target=test_target/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0bcaa-bd51-4974-98c9-222e1d700f57",
   "metadata": {},
   "source": [
    "Теперь можно попробовать обучить и оценить линейную регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc641c8-064b-4778-af27-3ec21d34ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of deviance explained: 0.6469789835863949\n",
      "MSE: 0.0012178112574176914\n"
     ]
    }
   ],
   "source": [
    "model1 = linear_model.TweedieRegressor(power=3,max_iter=1000)\n",
    "model1.fit(train,train_target)\n",
    "print('Percentage of deviance explained:',model1.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,model1.predict(test))\n",
    "print('MSE:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e18693-7c9e-47db-8ae9-ace93bdb6504",
   "metadata": {},
   "source": [
    "Нормально вроде. MSE по логике надо бы на 100 умножить, чтобы вернуться к тем данным, которые были до нормализации, но даже так получается, что ошибка в ~0.1 на 100 пунктов рейтинга. Лучшие результаты получились с power=3 и power=0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77892162-60d1-431f-b33b-c440ec975946",
   "metadata": {},
   "source": [
    "Дальше попробуем обучить деревья с разными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc9cc74-c6e0-4d8a-a288-ef44e8f5e62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree1 determination of the prediction: 0.9380054042189935\n",
      "Tree1 MSE: 0.00022313054499366287\n",
      "Tree2 determination of the prediction: 0.8875076473973315\n",
      "Tree2 MSE: 0.00040488174215247994\n"
     ]
    }
   ],
   "source": [
    "tree1=DecisionTreeRegressor()\n",
    "tree2=DecisionTreeRegressor(max_depth=5)\n",
    "tree1.fit(train,train_target)\n",
    "tree2.fit(train,train_target)\n",
    "print('Tree1 determination of the prediction:',tree1.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,tree1.predict(test))\n",
    "print('Tree1 MSE:',mse)\n",
    "print('Tree2 determination of the prediction:',tree2.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,tree2.predict(test))\n",
    "print('Tree2 MSE:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0961ad3-8b82-4278-b7aa-df459fe7ada4",
   "metadata": {},
   "source": [
    "Не очень удивительно, что деревья оказываются лучше, так как количество возможных значений потенциала ограничено, и его не так сложно раскидать по листьям дерева, хотя я всё равно немного удивлён, что по характеристикам игрока можно настолько точно предсказать его потенциал, хоть я и ждал, что это возможно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cdcc4b-e376-4906-bf20-6fb5b7b4a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination of the prediction: 0.834131182494441\n",
      "MSE: 0.0005969939666710235\n"
     ]
    }
   ],
   "source": [
    "model2=svm.LinearSVR(max_iter=20000,tol=0.01)\n",
    "model2.fit(train,train_target)\n",
    "print('Coefficient of determination of the prediction:',model2.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,model2.predict(test))\n",
    "print('MSE:',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8100ae72-3921-4860-bc9f-7204a4425dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination of the prediction: 0.7461936670879836\n",
      "MSE: 0.0009134980988593156\n"
     ]
    }
   ],
   "source": [
    "model3=KNeighborsRegressor()\n",
    "model3.fit(train,train_target)\n",
    "print('Coefficient of determination of the prediction:',model3.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,model3.predict(test))\n",
    "print('MSE:',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3ef01c-246a-4379-8396-f8dbf21b9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination of the prediction: 0.9521634000926337\n",
      "MSE: 0.00017217317854090444\n"
     ]
    }
   ],
   "source": [
    "model4=GradientBoostingRegressor(random_state=0)\n",
    "model4.fit(train,train_target)\n",
    "print('Coefficient of determination of the prediction:',model4.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,model4.predict(test))\n",
    "print('MSE:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb8646-8c47-4ba7-9b2c-11441ba76f74",
   "metadata": {},
   "source": [
    "А вот и новая лучшая модель, бустинг. Напоследок попробую нейронные сетки с разными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc21685-139b-4698-aad0-86b76346b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1 Coefficient of determination of the prediction: 0.9076535839915977\n",
      "NN1 MSE: 0.00033237261849329173\n",
      "NN2 Coefficient of determination of the prediction: 0.8510575580221\n",
      "NN2 MSE: 0.0005360726662145233\n",
      "NN3 Coefficient of determination of the prediction: 0.9088017030577434\n",
      "NN3 MSE: 0.00032824031583498153\n"
     ]
    }
   ],
   "source": [
    "nn1=MLPRegressor(max_iter=1000, solver='lbfgs',early_stopping=True)\n",
    "nn1.fit(train,train_target)\n",
    "print('NN1 Coefficient of determination of the prediction:',nn1.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,nn1.predict(test))\n",
    "print('NN1 MSE:',mse)\n",
    "nn2=MLPRegressor(max_iter=1000,batch_size=50)\n",
    "nn2.fit(train,train_target)\n",
    "print('NN2 Coefficient of determination of the prediction:',nn2.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,nn2.predict(test))\n",
    "print('NN2 MSE:',mse)\n",
    "nn3=MLPRegressor(max_iter=1000,hidden_layer_sizes=(100,100,100), solver='lbfgs',early_stopping=True)\n",
    "nn3.fit(train,train_target)\n",
    "print('NN3 Coefficient of determination of the prediction:',nn3.score(test,test_target))\n",
    "mse=mean_squared_error(test_target,nn3.predict(test))\n",
    "print('NN3 MSE:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b527a6-3b1d-42b9-bbad-5784aa5cca84",
   "metadata": {},
   "source": [
    "Подведём итоги проделанной работы.\n",
    "Были протестированы следующие модели (порядок такой же):\n",
    "1. Линейная регрессия на обратном распределении Гаусса;\n",
    "2. Дерево решений, одно без ограничения на глубину, одно с максимальной глубиной 5;\n",
    "3. Регрессия на методе опорных векторов (SVM);\n",
    "4. KNN регрессия с k=5;\n",
    "5. Градиентный бустинг;\n",
    "6. Нейронные сети, одна просто с lbfgs, одна с оптимизированным градиентным спуском (adam), одна с lbfgs и определённой вручную структурой.\n",
    "Из всех моделей лучший результат показали градиентный бустинг, дерево без ограничения на глубину и обе нейронные сети с lbfgs.\n",
    "\n",
    "В принципе из-за размера датасета (~16к строк) неудивительно, что lbfgs даёт лучший результат, ибо он ориентирован на небольшие датасеты.\n",
    "\n",
    "Ну и от себя добавлю, пожалуй, пару слов. Во-первых, никак не доходили руки чисто самому что-то сделать с моделями ML, немного разобрался с sklearn (да и вообще юпитер поставил себе в кои-то веки). Во-вторых, лишний раз подтвердилось моё мнение, что сложнее подготовить датасет, чем обучать на нём модели, ибо почти все модели - копипаст (но не потому что я не понимаю, что делать, а потому что реально код одинаковый, только название модели разное), а подготовку датасета пришлось руками писать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4186f-122f-4581-be46-3ea746d64d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
